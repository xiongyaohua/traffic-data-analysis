{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 期中练习\n",
    "\n",
    "## 要求\n",
    "\n",
    "检验对上半学期知识的掌握，课后自行完成，可查阅各种资料。\n",
    "\n",
    "### 如何提交\n",
    "\n",
    "- 复制本文件，文件名改为`教学班号-编号.ipynb`。例如刘国强同学是2班第15号，文件名应改为`2-15.ipynb`。\n",
    "- 在复制文件中答题，每道题的答案紧接题目。\n",
    "- 答题结束后commit该文件，并提交pull request。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习1\n",
    "\n",
    "为了分析自变量$x$和因变量$y$的关系，通过测量得到带误差的20个样本数据如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ 0.70846042, -0.68388789,  1.03780474,  1.08334621,  0.77026309,\n",
    "        0.19722004, -0.46819526, -0.45270204,  0.02362673,  0.06549472,\n",
    "        0.08898416,  0.59424455, -0.26400365,  0.2456922 ,  0.5114847 ,\n",
    "       -0.31604016, -1.49329364,  1.24112288,  1.01993764,  1.75634392])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([ 4.49682518,  3.5737603 ,  7.93568197,  3.58719009,  5.38341441,\n",
    "        5.47930021, -0.9861325 , -0.15686681,  2.36963799,  4.01600211,\n",
    "       -0.20329642,  3.07728831, -1.30408343,  2.84796441,  2.27915787,\n",
    "        2.62078689, -1.2855133 ,  4.39242028,  6.24385669,  6.00822241])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x269cbe78940>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOIklEQVR4nO3da2xk913G8efxOlZJaFXX65I2F28sRRWhbxqPoqERVUQrVLYVCxJIKSmUy2rVF+WO0EpI9BUvQAhRpAVptYBasWqFoEBVpW0CSoQq4agzudCkS+hi6ibd0LjGagEhvNb8eOFxcWfHnjPrOT6/c+b7kSyPfWZHz/5n95lz/ufmiBAAIK+ZqgMAAA5HUQNAchQ1ACRHUQNAchQ1ACQ3W8aLnjx5Mk6dOlXGSwNAI3W73W9ExOKwZaUU9alTp9TpdMp4aQBoJNvrBy1j6gMAkqOoASA5ihoAkqOoASC5QkVt+1dsv2D7edsft/2asoMBAHaNLGrbd0j6RUmtiHirpBOSHi47GABgV9Gpj1lJ32V7VtKtkq6VFwlAXXTXt3Thiavqrm9VHaXRRh5HHRFfs/17kr4q6X8kPRYRjw0+z/Y5Seck6e677550TgDJdNe39MilVW3v9DQ3O6PLZ9taWZqvOlYjFZn6mJd0RtI9kt4s6Tbb7x98XkRcjIhWRLQWF4eeXAOgQVbXNrW901MvpOs7Pa2ubVYdqbGKTH28S9K/RcRGRFyX9ElJby83FoDs2ssLmpud0QlLt8zOqL28UHWkxipyCvlXJbVt36rdqY93SuL8cGDKrSzN6/LZtlbXNtVeXmDao0RF5qifsv2Xkp6WtCPpGUkXyw4GIL+VpXkK+hgUuihTRHxY0odLzgIAGIIzEwEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoawNi661u68MRVdde3qo4yFWarDgCgXrrrW3rk0qq2d3qam53R5bNtrSzNVx2r0VijBjCW1bVNbe/01Avp+k5Pq2ubVUdqPIoawFjaywuam53RCUu3zM6ovbxQdaTGKzT1Yfv1ki5JequkkPRzEfGPJeYCkNTK0rwun21rdW1T7eUFpj2OQdE56o9I+mxE/LjtOUm3lpgJQHIrS/MU9IDu+lZpH14ji9r26yS9Q9LPSFJEbEvanmgKAKixsnewFpmjXpa0IenPbD9j+5Lt2yaWAABqruwdrEWKelbS/ZL+OCLeJum/JZ0ffJLtc7Y7tjsbGxsTDQkAmZW9g9URcfgT7NslrUbEqf7PPyDpfES856A/02q1otPpTDInAKR21Dlq292IaA1bNnKOOiL+3fZLtt8SES9KeqekL42dAgAarMwdrEWP+vgFSZf7R3ysSfrZUtIAAG5QqKgj4llJQ1fJAQDl4sxEAEiOogaA5ChqAEiOogaA5ChqTD0ugo/suHEAphoXwUcdsEaNqdbki+CzpdAcrFFjqu1do+H6Tq9RF8FnS6FZKGpMtaZeBH/YlkJT/m7TiKLG1GviRfCbuqUwrShqoIGauqUwrShqoKGauKUwrTjqAwCSo6gBIDmKGgCSo6gBIDmKGgCSo6gBIDmKGgCSo6gBIDmKGgCSo6gBIDmKGgCSo6gBIDmKGgCSo6iBmuOWW83HZU6BGuOWW9OBNWqgxpp0c162DA7GGjVQY0255RZbBoejqIEaa8ott7gZ7+EoaqDmmnDLraZsGZSFogZQuaZsGZSFogaQQhO2DMrCUR8AkFzhorZ9wvYztj9dZiAAwHcaZ436lyRdKSsIMCkcj4umKTRHbftOSe+R9NuSfrXURMARcDwumqjoGvUfSPoNSb2DnmD7nO2O7c7GxsYksgFja9KZesCekUVt+72SXo2I7mHPi4iLEdGKiNbi4uLEAgLj2Dse94TF8bhojCJTHw9K+hHbpyW9RtLrbP95RLy/3GjA+DgeF03kiCj+ZPshSb8eEe897HmtVis6nc7RkgHAFLHdjYjWsGUcRw0AyY11ZmJEPCnpyVKSAACGYo0aAJKjqAFMDCcblYOLMtVYd32LoxuQBicblYeirin+UyAbLv5fHqY+aooz8JANJxuVhzXqmuKOGMiGk43KM9YJL0VxwsvxYI4aaI7DTnhhjbrGuCMGMB2YowaA5ChqAEiOogaA5ChqAEiOogYS4lRs7MdRH0AynHWKQaxRA8lw1ikGUdRAMpyKjUFMfQDJcCo2BlHUwBBVn57PWafYj6IGBrAzD9kwRw0MYGcesqGogQHszEM2TH0AA9iZh2woahxZ1TveysDOPGRCUeNI2PEGlI85ahwJO96A8lHUOBJ2vAHlY+oDR8KON6B8FDWOrOodb03cmQnsR1Gj1tiZiWnAHDVqrc47M7k5AIpijRq1trcz8/pOr1Y7M9kSwDgoatRaXXdmDtsSqEt2HD+KGrVX9c7Mm1HXLQFUg6IGKlDXLQFUY2RR275L0sck3S6pJ+liRHyk7GBA09VxSwDVKLJGvSPp1yLiaduvldS1/XhEfKnkbAAAFTg8LyJeiYin+4//U9IVSXeUHQwAsGus46htn5L0NklPDVl2znbHdmdjY2NC8QAAhYva9ndL+itJvxwR3xpcHhEXI6IVEa3FxcVJZgSAqVaoqG3fot2SvhwRnyw3EgBgv5FFbduS/kTSlYj4/fIjAQD2K7JG/aCkn5L0g7af7X+dLjkXAKBv5OF5EfF5ST6GLACAIbh6HgAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHIUNQAkR1EDQHKFitr2u22/aPuq7fNlhwIA/L+RRW37hKQLkn5Y0n2S3mf7vrKDAQB2FVmjfkDS1YhYi4htSZ+QdKbcWACAPUWK+g5JL+37+eX+776D7XO2O7Y7Gxsbk8oHAFOvSFF7yO/ihl9EXIyIVkS0FhcXj54Mleiub+nCE1fVXd+qOgqAvtkCz3lZ0l37fr5T0rVy4qBK3fUtPXJpVds7Pc3Nzujy2bZWluarjnXTuutbWl3bVHt5odZ/D6BIUX9B0r2275H0NUkPS/rJUlOhEqtrm9re6akX0vWdnlbXNmtbcE370MF0Gzn1ERE7kj4k6XOSrkj6i4h4oexgOH7t5QXNzc7ohKVbZmfUXl6oOtJNG/ahA9RVkTVqRcSjkh4tOQsqtrI0r8tn242YLtj70Lm+06v9hw7giBv2Cx5Zq9WKTqcz8dcFxsEcNerEdjciWsOWFVqjBupoZWmegkYjcK0PAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiOosa3cXcXICcuygRJXGgfyIw1akjiQvtAZhQ1JDXr7i5A0zD1AUnNursL0DQUNb6NC+0DOTH1AQDJpSpqDg9rDt5LYHLSTH1weFhz8F4Ck5VmjZrDw5qD9xKYrDRFzeFhzcF7CUyWI2LiL9pqtaLT6Yz957rrWxwe1hC8l8B4bHcjojVsWZo5aonDw5qE9xKYnDRTHwCA4ShqAEiOogaA5ChqAEiOogaA5ChqAEiulOOobW9IWr+JP3pS0jcmHOe4kL0adc1e19wS2cuyFBGLwxaUUtQ3y3bnoAO+syN7Neqava65JbJXgakPAEiOogaA5LIV9cWqAxwB2atR1+x1zS2R/dilmqMGANwo2xo1AGAARQ0AyVVa1LZ/wvYLtnu2DzxkxvZXbH/R9rO2x7/QdQnGyP5u2y/avmr7/HFmPIjtN9h+3PaX+9+HXo80y7iPGkPv+sP+8n+yfX8VOYcpkP0h29/sj/Gztn+ripyDbP+p7VdtP3/A8sxjPip7yjE/VERU9iXpeyW9RdKTklqHPO8rkk5WmfVmsks6IelfJS1LmpP0nKT7EmT/XUnn+4/PS/qdrONeZAwlnZb0GUmW1Jb0VNVjPEb2hyR9uuqsQ7K/Q9L9kp4/YHnKMS+YPeWYH/ZV6Rp1RFyJiBerzHCzCmZ/QNLViFiLiG1Jn5B0pvx0I52R9NH+449K+tHqooxUZAzPSPpY7FqV9HrbbzruoENkff9Hioh/kPQfhzwl65gXyV47dZmjDkmP2e7aPld1mDHcIemlfT+/3P9d1b4nIl6RpP73Nx7wvAzjXmQMs45z0Vzfb/s525+x/X3HE+3Iso55UbUa89JvxWX77yTdPmTRb0bE3xZ8mQcj4prtN0p63PY/9z81SzWB7B7yu2M5HvKw7GO8TCXjPqDIGFY2ziMUyfW0dq/x8F+2T0v6G0n3lh1sArKOeRG1G/PSizoi3jWB17jW//6q7b/W7iZl6YUxgewvS7pr3893Srp2xNcs5LDstr9u+00R8Up/c/XVA16jknEfUGQMKxvnEUbmiohv7Xv8qO0/sn0yIrJeOGhP1jEfqY5jnn7qw/Zttl+791jSD0kaujc3oS9Iutf2PbbnJD0s6VMVZ5J2M3yg//gDkm7YOkg07kXG8FOSfrp/JEJb0jf3pnYqNjK77dttu//4Ae3+n9w89qTjyzrmI9VyzKvckynpx7T7yfy/kr4u6XP9379Z0qP9x8va3Vv+nKQXtDvtUPle2CLZ+z+flvQv2t37nyX7gqS/l/Tl/vc3ZB73YWMo6YOSPth/bEkX+su/qEOOIEqY/UP98X1O0qqkt1eduZ/r45JekXS9/+/852s05qOypxzzw744hRwAkks/9QEA046iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASO7/AOzUtBUYX86uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, Y, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 划分训练集和测试集\n",
    "\n",
    "将20个数据点划分为训练集和测试集，期中训练集为前15个数据点，测试集为后5个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集X: [ 0.70846042 -0.68388789  1.03780474  1.08334621  0.77026309  0.19722004\n",
      " -0.46819526 -0.45270204  0.02362673  0.06549472  0.08898416  0.59424455\n",
      " -0.26400365  0.2456922   0.5114847 ]\n",
      "训练集Y: [ 4.49682518  3.5737603   7.93568197  3.58719009  5.38341441  5.47930021\n",
      " -0.9861325  -0.15686681  2.36963799  4.01600211 -0.20329642  3.07728831\n",
      " -1.30408343  2.84796441  2.27915787]\n",
      "测试集X: [-0.31604016 -1.49329364  1.24112288  1.01993764  1.75634392]\n",
      "测试集Y: [ 2.62078689 -1.2855133   4.39242028  6.24385669  6.00822241]\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, Y_train = X[:15], Y[:15]\n",
    "X_test, Y_test = X[15:], Y[15:]\n",
    "\n",
    "print(\"训练集X:\", X_train)\n",
    "print(\"训练集Y:\", Y_train)\n",
    "print(\"测试集X:\", X_test)\n",
    "print(\"测试集Y:\", Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 数据建模\n",
    "\n",
    "分别用1到4次多项式函数作为模型拟合训练集中的数据，并分别计算每个模型与数据的均方差（MSE）。\n",
    "\n",
    "哪一个模型与训练数据拟合最好？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree = 1: MSE_train = 3.6141199809365916\n",
      "degree = 2: MSE_train = 3.4709875708912987\n",
      "degree = 3: MSE_train = 3.0102468155333737\n",
      "degree = 4: MSE_train = 2.397166165471182\n"
     ]
    }
   ],
   "source": [
    "# 定义多项式次数列表\n",
    "degree_list = [1, 2, 3, 4]\n",
    "\n",
    "# 计算每个模型的均方差（MSE）\n",
    "for degree in degree_list:\n",
    "    \n",
    "    # 拟合多项式回归模型\n",
    "    p = np.polyfit(X_train, Y_train, degree)\n",
    "    \n",
    "    # 计算训练集上的预测值\n",
    "    Y_pred_train = np.polyval(p, X_train)\n",
    "\n",
    "    # 计算MSE\n",
    "    mse_train = np.mean((Y_pred_train - Y_train) ** 2)\n",
    "    \n",
    "    print(\"degree = {}: MSE_train = {}\".format(degree, mse_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "较低的MSE表示模型与训练数据拟合得更好。因此，在给定的结果中，degree = 4 的模型具有最低的MSE（2.397166165471182），表明它与训练数据拟合得最好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 模型测试\n",
    "计算4个模型与测试数据的均方差，哪一个模型与测试数据拟合最好？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree = 1: MSE_test = 1.9373288022689124\n",
      "degree = 2: MSE_test = 6.924885916261641\n",
      "degree = 3: MSE_test = 145.53829178692047\n",
      "degree = 4: MSE_test = 2717.4997768004628\n"
     ]
    }
   ],
   "source": [
    "# 定义多项式次数列表\n",
    "degree_list = [1, 2, 3, 4]\n",
    "# 计算每个模型的均方差（MSE）\n",
    "for degree in degree_list:\n",
    "    \n",
    "    # 拟合多项式回归模型\n",
    "    p = np.polyfit(X_train, Y_train, degree)\n",
    "    \n",
    "    # 计算测试集上的预测值\n",
    "    Y_pred_test = np.polyval(p, X_test)\n",
    "\n",
    "    # 计算MSE\n",
    "    mse_test = np.mean((Y_pred_test - Y_test) ** 2)\n",
    "    \n",
    "    print(\"degree = {}: MSE_test = {}\".format(degree, mse_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "较低的MSE表示模型与测试数据拟合得更好。因此，在给定的结果中，degree = 1 的模型具有最低的MSE（1.9373288022689124），表明它与测试数据拟合得最好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2和1.3的答案是否相同？两者的异同有什么意义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答案不相同。根据给出的均方误差（Mean Squared Error, MSE）的结果，degree = 4 的模型在训练数据上拟合得更好，而degree = 1 的模型在测试数据上拟合得更好。\n",
    "\n",
    "这种情况表示degree = 4 的模型过拟合了训练数据，即在训练数据上表现出色，但在未见过的测试数据上表现较差。与之相反，degree = 1 的模型在测试数据上表现较好，可能更好地泛化到未见过的数据。\n",
    "\n",
    "这种差异的意义在于，我们希望训练出的模型能够在未见过的数据上具有良好的泛化能力。如果模型在训练数据上表现很好，但在测试数据上表现差，说明模型可能过拟合了训练数据，没有很好地捕捉数据的一般规律。因此，需要注意模型的选择和调优，以避免过拟合问题，从而在真实应用中获得更好的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习2 人工神经网络\n",
    "\n",
    "有如下神经网络：\n",
    "- 输入$x$是2维向量，输出$y$是1维标量\n",
    "- 包含两个全连接层\n",
    "    - 第一层有5个神经元，激活函数为sigmoid\n",
    "    - 第二层有1个神经元，激活函数为relu\n",
    "- 损失函数为均方差MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 写出公式\n",
    "\n",
    "- 写出relu、sigmoid函数的公式\n",
    "- 写出整个神经网络的公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid函数的公式：\n",
    "sigmoid(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "relu函数的公式： relu(x) = max(0, x)\n",
    "\n",
    "整个神经网络的公式：\n",
    "\n",
    "Z1 = X.dot(W1) + B1\n",
    "\n",
    "A1 = sigmoid(Z1)\n",
    "\n",
    "Z2 = A1.dot(W2) + B2\n",
    "\n",
    "Y_pred = relu(Z2)\n",
    "\n",
    "损失函数（均方差）的公式： L = (1/n) * sum((Y - Y_pred)^2)\n",
    "\n",
    "其中， X：输入数据（2维向量）\n",
    "\n",
    "Y：输出数据（1维标量）\n",
    "\n",
    "W1：第一层的权重参数（2x5矩阵）\n",
    "\n",
    "B1：第一层的偏置参数（5维向量）\n",
    "\n",
    "W2：第二层的权重参数（5x1矩阵）\n",
    "\n",
    "B2：第二层的偏置参数（1维标量）\n",
    "\n",
    "n：数据点的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 正向传播\n",
    "\n",
    "假设已知4个数据点的输入'X'，参考输出'Y'，参数'W_1'、'B_1'、'W_2'、'B_2'，。\n",
    "\n",
    "- 正向传播计算输出预测值'Y_pred'\n",
    "- 计算损失值'L'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-0.05025071,  1.12345037],\n",
    "       [-1.2771336 , -0.03387919],\n",
    "       [-0.06085093,  0.83960333],\n",
    "       [ 0.26666122, -0.15723225]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这里输入'x'表示为行向量，即'X'中每行表示一个数据点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([[ 0.34942997],\n",
    "       [ 0.09796396],\n",
    "       [ 1.80617515],\n",
    "       [-0.50698293]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(2,5)\n",
    "b1 = np.random.randn(5)\n",
    "W2 = np.random.randn(5,1)\n",
    "b2 = np.random.randn(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[-0.15772071,  2.4169384 ,  1.18656177,  0.74048303,  0.95473468],\n",
    "       [ 1.75613621,  0.44768404,  0.25003215,  0.52863169, -0.75204543]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.array([-1.00393578, -0.19942106, -1.23939537,  1.62336519, -0.21580562])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.array([[ 0.8173788 ],\n",
    "       [-0.01165333],\n",
    "       [ 1.10703394],\n",
    "       [ 0.90372372],\n",
    "       [ 0.86510315]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = np.array([[0.277288]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.18514844],\n",
       "        [1.35081552],\n",
       "        [2.09965131],\n",
       "        [1.98338406]]),\n",
       " 2.80688883177308)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正向传播计算输出预测值 Y_pred\n",
    "Z1 = X.dot(W1) + b1\n",
    "A1 = 1 / (1 + np.exp(-Z1))\n",
    "Z2 = A1.dot(W2) + b2\n",
    "Y_pred = np.maximum(0, Z2)\n",
    "\n",
    "# 计算损失值 L\n",
    "n = len(X)\n",
    "L = (1/n) * np.sum((Y - Y_pred)**2)\n",
    "\n",
    "Y_pred, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 方向传播\n",
    "\n",
    "计算损失值'L'对参数'W_1'、'B_1'、'W_2'、'B_2'的偏导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.10062818, -0.00045547,  0.01227741, -0.12888547, -0.04684264],\n",
       "        [ 0.16104007, -0.00277893,  0.20342634,  0.06970365,  0.14329457]]),\n",
       " array([ 0.45340951, -0.00683274,  0.54292804,  0.35971905,  0.52730517]),\n",
       " array([[1.20554195],\n",
       "        [1.33518175],\n",
       "        [0.66155887],\n",
       "        [2.42607152],\n",
       "        [1.0643283 ]]),\n",
       " array([2.93620659]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 反向传播计算损失值 L 对参数 W1, b1, W2, b2 的偏导数\n",
    "\n",
    "dL_dY_pred = 2/n * (Y_pred - Y)\n",
    "dL_dZ2 = dL_dY_pred * (Z2 > 0)\n",
    "dL_dW2 = np.dot(A1.T, dL_dZ2)\n",
    "dL_db2 = np.sum(dL_dZ2, axis=0)\n",
    "dL_dA1 = np.dot(dL_dZ2, W2.T)\n",
    "dL_dZ1 = dL_dA1 * A1 * (1 - A1)\n",
    "dL_dW1 = np.dot(X.T, dL_dZ1)\n",
    "dL_db1 = np.sum(dL_dZ1, axis=0)\n",
    "\n",
    "dL_dW1, dL_db1, dL_dW2, dL_db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
